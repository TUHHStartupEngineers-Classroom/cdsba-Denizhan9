[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Lab Journal",
    "section": "",
    "text": "This is a template example for lab journaling. Students in the data science courses at the Institute of Entrepreneurship will use this template to learn R for business analytics. Students can replace this text as they wish."
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "My Lab Journal",
    "section": "How to use",
    "text": "How to use\n\nAccept the assignment and get your own github repo.\nBlog/journal what you are doing in R, by editing the .qmd files.\nSee the links page for lots of helpful links on learning R.\nChange everything to make it your own.\nMake sure to render you website every time before you want to upload changes."
  },
  {
    "objectID": "content/01_journal/09_iv.html",
    "href": "content/01_journal/09_iv.html",
    "title": "Instrumental Variables",
    "section": "",
    "text": "library(tidyverse)\nlibrary(dagitty)\nlibrary(ggdag)\ndf &lt;- readRDS(\"data/rand_enc.rds\")\n\niv_enc &lt;- dagify(\n  Y ~ D,\n  Y ~ U,\n  D ~ U,\n  D ~ Z,\n  latent = \"U\",\n  outcome = \"Y\",\n  exposure = \"D\",\n  coords = list(x = c(U = 1, D = 0.5, Y = 1.5, Z = 0),\n                y = c(U = 0, D = 1, Y = 1, Z = 1)),\n  labels = c(\"D\" = \"Used feature\", \n             \"Y\" = \"Time on app\", \n             \"U\" = \"Unobserved characteristics\",\n             \"Z\" = \"Random encouragement\")\n)\nggdag(iv_enc, text = T) +\n#  guides(color = \"none\") +\n  geom_dag_text(color = \"white\") +\n  geom_dag_edges(edge_color = \"black\") +\n  geom_dag_label_repel(aes(label = label))\n\n\n\n\n\n\n\n\n\n# Load the data\nrand_enc_data &lt;- readRDS(\"data/rand_enc.rds\")\n\n# Task 2: Compute the naive, biased estimate\nnaive_model &lt;- lm(time_spent ~ used_ftr, data = rand_enc_data)\nsummary(naive_model)\n\n\nCall:\nlm(formula = time_spent ~ used_ftr, data = rand_enc_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-20.4950  -3.5393   0.0158   3.5961  20.5051 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 18.86993    0.06955   271.3   &lt;2e-16 ***\nused_ftr    10.82269    0.10888    99.4   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.351 on 9998 degrees of freedom\nMultiple R-squared:  0.497, Adjusted R-squared:  0.497 \nF-statistic:  9881 on 1 and 9998 DF,  p-value: &lt; 2.2e-16\n\n# Task 3: Assumption Testing\n# No assumptions related to correlations can be tested with the available data.\n\n# Task 4: Instrumental Variable Estimation\n# Assuming Z is the instrument (replace Z with the actual instrument variable)\nfirst_stage &lt;- lm(used_ftr ~ rand_enc, data = rand_enc_data)\nsummary(first_stage)\n\n\nCall:\nlm(formula = used_ftr ~ rand_enc, data = rand_enc_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.5071 -0.3062 -0.3062  0.4929  0.6938 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.306164   0.006851   44.69   &lt;2e-16 ***\nrand_enc    0.200940   0.009624   20.88   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4811 on 9998 degrees of freedom\nMultiple R-squared:  0.04178,   Adjusted R-squared:  0.04169 \nF-statistic:   436 on 1 and 9998 DF,  p-value: &lt; 2.2e-16\n\n# Second Stage (2SLS)\nsecond_stage &lt;- lm(time_spent ~ fitted(first_stage), data = rand_enc_data)\nsummary(second_stage)\n\n\nCall:\nlm(formula = time_spent ~ fitted(first_stage), data = rand_enc_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.8757  -5.4714  -0.3263   5.3807  25.6541 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)          19.3124     0.3129   61.72   &lt;2e-16 ***\nfitted(first_stage)   9.7382     0.7447   13.08   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 7.482 on 9998 degrees of freedom\nMultiple R-squared:  0.01681,   Adjusted R-squared:  0.01672 \nF-statistic:   171 on 1 and 9998 DF,  p-value: &lt; 2.2e-16\n\n# Compare naive estimate with IV estimate\nnaive_coefficient &lt;- coef(naive_model)[\"used_ftr\"]\niv_coefficient &lt;- coef(second_stage)[\"fitted(first_stage)\"]\n\ncat(\"Naive Estimate: \", naive_coefficient, \"\\n\")\n\nNaive Estimate:  10.82269 \n\ncat(\"IV Estimate: \", iv_coefficient, \"\\n\")\n\nIV Estimate:  9.738175"
  },
  {
    "objectID": "content/01_journal/07_matching.html",
    "href": "content/01_journal/07_matching.html",
    "title": "Matching and Subclassification",
    "section": "",
    "text": "library(tidyverse)\nlibrary(dagitty)\nlibrary(ggdag)\ndf &lt;- readRDS((\"data/membership.rds\"))\n\ndag_model &lt;- 'dag {\nbb=\"0,0,1,1\"\nage [pos=\"0.2,0.2\"]\nsex [pos=\"0.3,0.2\"]\ncard [exposure,pos=\"0.3,0.6\"]\navg_pur [outcome,pos=\"0.4,0.4\"]\npre_avg_pur [pos=\"0.2,0.6\"]\ncard -&gt; avg_pur\npre_avg_pur -&gt; Avg_purch\npre_avg_pur -&gt; card\nage -&gt; card\nage -&gt; pre_avg_pur\nsex -&gt; card\nsex -&gt; pre_avg_pur\n}\n'\n# draw DAG\nggdag_status(dag_model) +\n  guides(fill = \"none\", color = \"none\") +  # Disable the legend\n  geom_dag_edges(edge_color = \"black\")\n\nWarning: Removed 1 rows containing missing values (`geom_dag_point()`).\n\n\nWarning: Removed 1 rows containing missing values (`geom_dag_text()`).\n\n\n\n\n\n\n\n\n\n\nlibrary(MatchIt)\nlibrary(dplyr)\nlibrary(Matching)\n\n\n# Load your data\ndata &lt;- readRDS(\"data/membership.rds\")\n\n# Assignment 2: Linear Regression Model\nmodel_linear &lt;- lm(avg_purch ~ card, data = data)\nsummary(model_linear)\n\n\nCall:\nlm(formula = avg_purch ~ card, data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-101.515  -20.684   -0.199   20.424  120.166 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  65.9397     0.3965  166.29   &lt;2e-16 ***\ncard         25.2195     0.6095   41.38   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 30.11 on 9998 degrees of freedom\nMultiple R-squared:  0.1462,    Adjusted R-squared:  0.1461 \nF-statistic:  1712 on 1 and 9998 DF,  p-value: &lt; 2.2e-16\n\n# Assignment 3: Causal Inference Analysis\ncem_match &lt;- matchit(card ~ pre_avg_purch + age + sex,\n                     data = data,\n                     method = 'cem',\n                     estimand = 'ATE')\ndata_cem &lt;- match.data(cem_match)\nmodel_cem &lt;- lm(avg_purch ~ card, data = data_cem, weights = weights)\nsummary(model_cem)\n\n\nCall:\nlm(formula = avg_purch ~ card, data = data_cem, weights = weights)\n\nWeighted Residuals:\n     Min       1Q   Median       3Q      Max \n-159.349  -20.459   -0.151   19.863  161.528 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  69.9896     0.3984  175.66   &lt;2e-16 ***\ncard         15.2043     0.6137   24.77   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 30.12 on 9878 degrees of freedom\nMultiple R-squared:  0.0585,    Adjusted R-squared:  0.0584 \nF-statistic: 613.7 on 1 and 9878 DF,  p-value: &lt; 2.2e-16\n\nnn_match &lt;- matchit(card ~ pre_avg_purch + age + sex,\n                    data = data,\n                    method = \"nearest\",\n                    distance = \"mahalanobis\",\n                    replace = TRUE)\ndata_nn &lt;- match.data(nn_match)\nmodel_nn &lt;- lm(pre_avg_purch ~ card, data = data_nn, weights = weights)\nsummary(model_nn)\n\n\nCall:\nlm(formula = pre_avg_purch ~ card, data = data_nn, weights = weights)\n\nWeighted Residuals:\n    Min      1Q  Median      3Q     Max \n-85.464 -19.097  -1.866  16.325 124.497 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  76.2937     0.5065 150.616   &lt;2e-16 ***\ncard          0.1001     0.6472   0.155    0.877    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 26.21 on 6907 degrees of freedom\nMultiple R-squared:  3.462e-06, Adjusted R-squared:  -0.0001413 \nF-statistic: 0.02391 on 1 and 6907 DF,  p-value: 0.8771\n\npropensity_model &lt;- glm(card ~ pre_avg_purch + age + sex,\n                        data = data,\n                        family = binomial(link = \"logit\"))\ndata_augmented &lt;- data %&gt;% mutate(propensity_score = predict(propensity_model, type = \"response\"))\n\n\ndata_ipw &lt;- data_augmented %&gt;% mutate(\n  ipw_score = (card / propensity_score) + ((1 - card) / (1 - propensity_score))\n)\n\nmodel_ipw &lt;- lm(avg_purch ~ card, data = data_ipw, weights = ipw_score)\nsummary(model_ipw)\n\n\nCall:\nlm(formula = avg_purch ~ card, data = data_ipw, weights = ipw_score)\n\nWeighted Residuals:\n     Min       1Q   Median       3Q      Max \n-205.353  -28.995   -0.275   28.787  214.307 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  70.2628     0.4320  162.66   &lt;2e-16 ***\ncard         14.9573     0.6109   24.48   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 43.19 on 9998 degrees of freedom\nMultiple R-squared:  0.05657,   Adjusted R-squared:  0.05647 \nF-statistic: 599.5 on 1 and 9998 DF,  p-value: &lt; 2.2e-16\n\nmodel_ipw_trim &lt;- lm(avg_purch ~ card,\n                     data = data_ipw %&gt;% filter(propensity_score %&gt;% between(0.15, 0.85)),\n                     weights = ipw_score)\nsummary(model_ipw_trim)\n\n\nCall:\nlm(formula = avg_purch ~ card, data = data_ipw %&gt;% filter(propensity_score %&gt;% \n    between(0.15, 0.85)), weights = ipw_score)\n\nWeighted Residuals:\n     Min       1Q   Median       3Q      Max \n-205.353  -28.995   -0.275   28.787  214.307 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  70.2628     0.4320  162.66   &lt;2e-16 ***\ncard         14.9573     0.6109   24.48   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 43.19 on 9998 degrees of freedom\nMultiple R-squared:  0.05657,   Adjusted R-squared:  0.05647 \nF-statistic: 599.5 on 1 and 9998 DF,  p-value: &lt; 2.2e-16\n\nmodel_summary &lt;- modelsummary::modelsummary(list(\"Naive\" = model_linear,\n                                                 \"CEM\" = model_cem,\n                                                 \"NN\" = model_nn,\n                                                 \"IPW1\" = model_ipw,\n                                                 \"IPW2\" = model_ipw_trim))\nmodel_summary\n\n\n\n\n\nNaive\nCEM\nNN\n IPW1\n IPW2\n\n\n\n\n(Intercept)\n65.940\n69.990\n76.294\n70.263\n70.263\n\n\n\n(0.397)\n(0.398)\n(0.507)\n(0.432)\n(0.432)\n\n\ncard\n25.220\n15.204\n0.100\n14.957\n14.957\n\n\n\n(0.610)\n(0.614)\n(0.647)\n(0.611)\n(0.611)\n\n\nNum.Obs.\n10000\n9880\n6909\n10000\n10000\n\n\nR2\n0.146\n0.058\n0.000\n0.057\n0.057\n\n\nR2 Adj.\n0.146\n0.058\n0.000\n0.056\n0.056\n\n\nAIC\n96483.2\n95595.0\n65071.1\n97072.1\n97072.1\n\n\nBIC\n96504.8\n95616.6\n65091.6\n97093.7\n97093.7\n\n\nLog.Lik.\n-48238.590\n-47794.497\n-32532.552\n-48533.031\n-48533.031\n\n\nRMSE\n30.11\n30.08\n26.07\n30.54\n30.54"
  },
  {
    "objectID": "content/01_journal/05_dag.html",
    "href": "content/01_journal/05_dag.html",
    "title": "Directed Acyclic Graphs",
    "section": "",
    "text": "##Assignment\n\nlibrary(tidyverse)\nlibrary(dagitty)\nlibrary(ggdag)\ndag &lt;- dagify(\n  X ~ Z,\n  Y ~ Z,\n  Y ~ X,\n  coords = list(x = c(Y = 3, Z = 2, X = 1),\n                y = c(Y = 0, Z = 1, X = 0)),\n  labels = list(X = \"Parking spots\",\n                Y = \"Sales\",\n                Z = \"Customers\")\n)\n\n# Plot DAG\nggdag(dag) +\n  geom_dag_text(color = \"white\") +\n  geom_dag_edges(edge_color = \"black\") +\n  geom_dag_label_repel(aes(label = label))\n\n\n\n\n\n\n\n\n\n# Load necessary libraries\nlibrary(ggplot2)\nlibrary(dagitty)\n\n# Load the data\ndata &lt;- readRDS(\"C:\\\\Users\\\\Deniz\\\\Documents\\\\GitHub\\\\Causal_Data_Science_Data\\\\customer_sat.rds\")\n\n# Explore the data\nhead(data)\n\n# A tibble: 6 × 3\n  follow_ups satisfaction subscription\n       &lt;dbl&gt;        &lt;dbl&gt; &lt;chr&gt;       \n1          8           40 Elite       \n2          7           45 Elite       \n3          8           47 Elite       \n4          9           44 Elite       \n5         10           50 Elite       \n6          6           55 Premium+    \n\nsummary(data)\n\n   follow_ups      satisfaction   subscription      \n Min.   : 0.000   Min.   :40.00   Length:15         \n 1st Qu.: 2.500   1st Qu.:48.50   Class :character  \n Median : 7.000   Median :60.00   Mode  :character  \n Mean   : 5.667   Mean   :60.13                     \n 3rd Qu.: 8.000   3rd Qu.:72.00                     \n Max.   :10.000   Max.   :80.00                     \n\n# Regression without accounting for subscription\nmodel1 &lt;- lm(satisfaction ~ follow_ups, data = data)\nsummary(model1)\n\n\nCall:\nlm(formula = satisfaction ~ follow_ups, data = data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-12.412  -5.257   1.733   4.506  12.588 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  78.8860     4.2717  18.467 1.04e-10 ***\nfollow_ups   -3.3093     0.6618  -5.001 0.000243 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 7.923 on 13 degrees of freedom\nMultiple R-squared:  0.658, Adjusted R-squared:  0.6316 \nF-statistic: 25.01 on 1 and 13 DF,  p-value: 0.0002427\n\n# Regression accounting for subscription\nmodel2 &lt;- lm(satisfaction ~ follow_ups + subscription, data = data)\nsummary(model2)\n\n\nCall:\nlm(formula = satisfaction ~ follow_ups + subscription, data = data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.3222 -2.1972  0.3167  2.2667  3.9944 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           26.7667     6.6804   4.007  0.00206 ** \nfollow_ups             2.1944     0.7795   2.815  0.01682 *  \nsubscriptionPremium   44.7222     5.6213   7.956 6.88e-06 ***\nsubscriptionPremium+  18.0722     2.1659   8.344 4.37e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.958 on 11 degrees of freedom\nMultiple R-squared:  0.9597,    Adjusted R-squared:  0.9487 \nF-statistic: 87.21 on 3 and 11 DF,  p-value: 5.956e-08\n\n\nModel 1:\nIntercept = 78.9\nFollow-up coefficient = -3.3\nModel 2:\nIntercept = 26.8\nFollow-up coefficient = 2.2 Subscription Premium coefficient = 44.7 Subscription Premium+ coefficient = 18.1\nIn the model without accounting for subscription (model1), the negative coefficient for follow-up calls suggests that more follow-up calls are associated with lower satisfaction. However, this might be confounded by the type of subscription.\nIn the model accounting for subscription (model2), the positive coefficient for follow-up calls suggests that, after accounting for subscription type, more follow-up calls are associated with higher satisfaction.\nThe positive coefficients for the “Premium” and “Premium+” subscription levels suggest that clients with these subscriptions tend to report higher satisfaction compared to the reference level.\n\n# Plot the data\nggplot(data, aes(x = follow_ups, y = satisfaction, color = subscription)) +\n  geom_point(size = 3) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(title = \"Relationship Between Follow-up Calls and Satisfaction\",\n       x = \"Number of Follow-up Calls\",\n       y = \"Satisfaction\") +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "content/01_journal/03_regression.html",
    "href": "content/01_journal/03_regression.html",
    "title": "Regression and Statistical Inference",
    "section": "",
    "text": "#Assingment Chapter 3\n##Dimensions of dataframe\n\ndf &lt;- readRDS(\"data/car_prices.rds\")\ndim(df)\n\n[1] 181  22\n\nView(df)\ncat(\"Dimensions: \", dim(df), \"\\n\")\n\nDimensions:  181 22 \n\n\nThe dimensions are 181 x 22\n##Data types of Dataframe\n\nsummary(df)\n\n  aspiration         doornumber          carbody           drivewheel       \n Length:181         Length:181         Length:181         Length:181        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n enginelocation       wheelbase        carlength        carwidth    \n Length:181         Min.   : 86.60   Min.   :141.1   Min.   :60.30  \n Class :character   1st Qu.: 94.50   1st Qu.:166.3   1st Qu.:64.00  \n Mode  :character   Median : 96.50   Median :173.0   Median :65.40  \n                    Mean   : 98.21   Mean   :173.3   Mean   :65.74  \n                    3rd Qu.:100.40   3rd Qu.:180.2   3rd Qu.:66.50  \n                    Max.   :120.90   Max.   :208.1   Max.   :72.30  \n   carheight       curbweight    enginetype        cylindernumber    \n Min.   :47.80   Min.   :1488   Length:181         Length:181        \n 1st Qu.:52.00   1st Qu.:2122   Class :character   Class :character  \n Median :53.70   Median :2410   Mode  :character   Mode  :character  \n Mean   :53.58   Mean   :2521                                        \n 3rd Qu.:55.50   3rd Qu.:2910                                        \n Max.   :59.80   Max.   :4066                                        \n   enginesize     fuelsystem          boreratio         stroke    \n Min.   : 61.0   Length:181         Min.   :2.540   Min.   :2.07  \n 1st Qu.: 98.0   Class :character   1st Qu.:3.150   1st Qu.:3.08  \n Median :120.0   Mode  :character   Median :3.310   Median :3.23  \n Mean   :127.1                      Mean   :3.325   Mean   :3.23  \n 3rd Qu.:141.0                      3rd Qu.:3.590   3rd Qu.:3.40  \n Max.   :326.0                      Max.   :3.940   Max.   :4.17  \n compressionratio   horsepower       peakrpm        citympg     \n Min.   : 7.000   Min.   : 48.0   Min.   :4200   Min.   :13.00  \n 1st Qu.: 8.500   1st Qu.: 70.0   1st Qu.:4800   1st Qu.:19.00  \n Median : 9.000   Median : 95.0   Median :5200   Median :24.00  \n Mean   : 8.848   Mean   :106.2   Mean   :5182   Mean   :24.85  \n 3rd Qu.: 9.400   3rd Qu.:116.0   3rd Qu.:5500   3rd Qu.:30.00  \n Max.   :11.500   Max.   :288.0   Max.   :6600   Max.   :49.00  \n   highwaympg        price      \n Min.   :16.00   Min.   : 5118  \n 1st Qu.:25.00   1st Qu.: 7609  \n Median :30.00   Median : 9980  \n Mean   :30.48   Mean   :12999  \n 3rd Qu.:34.00   3rd Qu.:16430  \n Max.   :54.00   Max.   :45400  \n\nstr(df)\n\nClasses 'tbl_df', 'tbl' and 'data.frame':   181 obs. of  22 variables:\n $ aspiration      : chr  \"std\" \"std\" \"std\" \"std\" ...\n $ doornumber      : chr  \"two\" \"two\" \"two\" \"four\" ...\n $ carbody         : chr  \"convertible\" \"convertible\" \"hatchback\" \"sedan\" ...\n $ drivewheel      : chr  \"rwd\" \"rwd\" \"rwd\" \"fwd\" ...\n $ enginelocation  : chr  \"front\" \"front\" \"front\" \"front\" ...\n $ wheelbase       : num  88.6 88.6 94.5 99.8 99.4 ...\n $ carlength       : num  169 169 171 177 177 ...\n $ carwidth        : num  64.1 64.1 65.5 66.2 66.4 66.3 71.4 71.4 71.4 67.9 ...\n $ carheight       : num  48.8 48.8 52.4 54.3 54.3 53.1 55.7 55.7 55.9 52 ...\n $ curbweight      : num  2548 2548 2823 2337 2824 ...\n $ enginetype      : chr  \"dohc\" \"dohc\" \"ohcv\" \"ohc\" ...\n $ cylindernumber  : chr  \"four\" \"four\" \"six\" \"four\" ...\n $ enginesize      : num  130 130 152 109 136 136 136 136 131 131 ...\n $ fuelsystem      : chr  \"mpfi\" \"mpfi\" \"mpfi\" \"mpfi\" ...\n $ boreratio       : num  3.47 3.47 2.68 3.19 3.19 3.19 3.19 3.19 3.13 3.13 ...\n $ stroke          : num  2.68 2.68 3.47 3.4 3.4 3.4 3.4 3.4 3.4 3.4 ...\n $ compressionratio: num  9 9 9 10 8 8.5 8.5 8.5 8.3 7 ...\n $ horsepower      : num  111 111 154 102 115 110 110 110 140 160 ...\n $ peakrpm         : num  5000 5000 5000 5500 5500 5500 5500 5500 5500 5500 ...\n $ citympg         : num  21 21 19 24 18 19 19 19 17 16 ...\n $ highwaympg      : num  27 27 26 30 22 25 25 25 20 22 ...\n $ price           : num  13495 16500 16500 13950 17450 ...\n\n\nNumbers are defined as (“num”) and strings (“chr”).\n##Linear regression\n\nLG &lt;- lm(price ~., data = df)\nsummary(LG)\n\n\nCall:\nlm(formula = price ~ ., data = df)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -5662  -1120      0    798   9040 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)          -36269.965  15460.866  -2.346 0.020354 *  \naspirationturbo        1846.206   1041.391   1.773 0.078386 .  \ndoornumbertwo           242.523    571.929   0.424 0.672172    \ncarbodyhardtop        -3691.743   1424.825  -2.591 0.010561 *  \ncarbodyhatchback      -3344.335   1238.359  -2.701 0.007757 ** \ncarbodysedan          -2292.820   1356.014  -1.691 0.093043 .  \ncarbodywagon          -3427.921   1490.285  -2.300 0.022885 *  \ndrivewheelfwd          -504.564   1076.623  -0.469 0.640030    \ndrivewheelrwd           -15.446   1268.070  -0.012 0.990299    \nenginelocationrear     6643.492   2572.275   2.583 0.010806 *  \nwheelbase               -30.197     92.776  -0.325 0.745294    \ncarlength               -29.740     51.672  -0.576 0.565824    \ncarwidth                731.819    244.533   2.993 0.003258 ** \ncarheight               123.195    134.607   0.915 0.361617    \ncurbweight                2.612      1.781   1.467 0.144706    \nenginetypedohcv       -8541.957   4749.685  -1.798 0.074219 .  \nenginetypel             978.748   1786.384   0.548 0.584619    \nenginetypeohc          3345.252    933.001   3.585 0.000461 ***\nenginetypeohcf          972.919   1625.631   0.598 0.550462    \nenginetypeohcv        -6222.322   1236.415  -5.033 1.43e-06 ***\ncylindernumberfive   -11724.540   3019.192  -3.883 0.000157 ***\ncylindernumberfour   -11549.326   3177.177  -3.635 0.000387 ***\ncylindernumbersix     -7151.398   2247.230  -3.182 0.001793 ** \ncylindernumberthree   -4318.929   4688.833  -0.921 0.358545    \ncylindernumbertwelve -11122.209   4196.494  -2.650 0.008946 ** \nenginesize              125.934     26.541   4.745 5.00e-06 ***\nfuelsystem2bbl          177.136    883.615   0.200 0.841400    \nfuelsystemmfi         -3041.018   2576.996  -1.180 0.239934    \nfuelsystemmpfi          359.278   1001.529   0.359 0.720326    \nfuelsystemspdi        -2543.890   1363.546  -1.866 0.064140 .  \nfuelsystemspfi          514.766   2499.229   0.206 0.837107    \nboreratio             -1306.740   1642.221  -0.796 0.427516    \nstroke                -4527.137    922.732  -4.906 2.49e-06 ***\ncompressionratio       -737.901    555.960  -1.327 0.186539    \nhorsepower               10.293     22.709   0.453 0.651035    \npeakrpm                   2.526      0.634   3.983 0.000108 ***\ncitympg                 -90.352    166.647  -0.542 0.588538    \nhighwaympg              154.858    167.148   0.926 0.355761    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2189 on 143 degrees of freedom\nMultiple R-squared:  0.9415,    Adjusted R-squared:  0.9264 \nF-statistic: 62.21 on 37 and 143 DF,  p-value: &lt; 2.2e-16\n\n\nIf the coefficient estimate is negative that means that if the value of the variable increases the price of the car decreases. If the coefficient is positive the price increases if the variable is increased.\nThe p-value indicates the significance of the variable if the p-value is very small e.g. enginetypeohcv&lt; 0.001 that means that the variable is highly statically significant. The smaller the p-value the higher the statistical significance.\n##Linear regression 2 Regressor is enginelocationrear\nThe datatype is a string. It can have either the value front or rear. The coefficient estimate is positive that means that cars having a rear engine location tend to have higher prices than cars that have a front engine. The p-value is less than 0.05 therefore indicating that it is statisically significant\n##Add variable\n\nlibrary(dplyr)\n\n\nAttache Paket: 'dplyr'\n\n\nDie folgenden Objekte sind maskiert von 'package:stats':\n\n    filter, lag\n\n\nDie folgenden Objekte sind maskiert von 'package:base':\n\n    intersect, setdiff, setequal, union\n\nmut_df &lt;- df %&gt;% mutate(seat_heating = TRUE)\nmodel &lt;- lm(price ~ ., data = mut_df)\nsummary(model)\n\n\nCall:\nlm(formula = price ~ ., data = mut_df)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -5662  -1120      0    798   9040 \n\nCoefficients: (1 not defined because of singularities)\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)          -36269.965  15460.866  -2.346 0.020354 *  \naspirationturbo        1846.206   1041.391   1.773 0.078386 .  \ndoornumbertwo           242.523    571.929   0.424 0.672172    \ncarbodyhardtop        -3691.743   1424.825  -2.591 0.010561 *  \ncarbodyhatchback      -3344.335   1238.359  -2.701 0.007757 ** \ncarbodysedan          -2292.820   1356.014  -1.691 0.093043 .  \ncarbodywagon          -3427.921   1490.285  -2.300 0.022885 *  \ndrivewheelfwd          -504.564   1076.623  -0.469 0.640030    \ndrivewheelrwd           -15.446   1268.070  -0.012 0.990299    \nenginelocationrear     6643.492   2572.275   2.583 0.010806 *  \nwheelbase               -30.197     92.776  -0.325 0.745294    \ncarlength               -29.740     51.672  -0.576 0.565824    \ncarwidth                731.819    244.533   2.993 0.003258 ** \ncarheight               123.195    134.607   0.915 0.361617    \ncurbweight                2.612      1.781   1.467 0.144706    \nenginetypedohcv       -8541.957   4749.685  -1.798 0.074219 .  \nenginetypel             978.748   1786.384   0.548 0.584619    \nenginetypeohc          3345.252    933.001   3.585 0.000461 ***\nenginetypeohcf          972.919   1625.631   0.598 0.550462    \nenginetypeohcv        -6222.322   1236.415  -5.033 1.43e-06 ***\ncylindernumberfive   -11724.540   3019.192  -3.883 0.000157 ***\ncylindernumberfour   -11549.326   3177.177  -3.635 0.000387 ***\ncylindernumbersix     -7151.398   2247.230  -3.182 0.001793 ** \ncylindernumberthree   -4318.929   4688.833  -0.921 0.358545    \ncylindernumbertwelve -11122.209   4196.494  -2.650 0.008946 ** \nenginesize              125.934     26.541   4.745 5.00e-06 ***\nfuelsystem2bbl          177.136    883.615   0.200 0.841400    \nfuelsystemmfi         -3041.018   2576.996  -1.180 0.239934    \nfuelsystemmpfi          359.278   1001.529   0.359 0.720326    \nfuelsystemspdi        -2543.890   1363.546  -1.866 0.064140 .  \nfuelsystemspfi          514.766   2499.229   0.206 0.837107    \nboreratio             -1306.740   1642.221  -0.796 0.427516    \nstroke                -4527.137    922.732  -4.906 2.49e-06 ***\ncompressionratio       -737.901    555.960  -1.327 0.186539    \nhorsepower               10.293     22.709   0.453 0.651035    \npeakrpm                   2.526      0.634   3.983 0.000108 ***\ncitympg                 -90.352    166.647  -0.542 0.588538    \nhighwaympg              154.858    167.148   0.926 0.355761    \nseat_heatingTRUE             NA         NA      NA       NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2189 on 143 degrees of freedom\nMultiple R-squared:  0.9415,    Adjusted R-squared:  0.9264 \nF-statistic: 62.21 on 37 and 143 DF,  p-value: &lt; 2.2e-16\n\n\nThe output for some reason shows NA which I don’t understand. I would expect the p-value to be 0 resulting to the seat heating having an extremely low significance on the price. Which makes sense when you consider that all cars in the dataframe use it."
  },
  {
    "objectID": "content/01_journal/01_probability.html",
    "href": "content/01_journal/01_probability.html",
    "title": "Probability Theory",
    "section": "",
    "text": "Note\n\n\n\nYou can delete everything in here and start fresh.\n\n\nThis is a .qmd file. It is plain text with special features. Any time you write just like this, it will be compiled to normal text in the website. If you put a # in front of your text, it will create a top level-header.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites.\n\n1 Assingment 1\n\nT_scope_on_time&lt;-0.2\nT_scope_not_time&lt;-0.8\nT_on_time&lt;-0.6\nT_not_time&lt;-0.4\nP_scope&lt;-0.3\nP_no_scope&lt;-0.7\n\nP_T_S&lt;-P_scope*T_scope_on_time\nP_T_nS&lt;-P_no_scope*T_on_time\nP_nT_S&lt;-P_scope*T_scope_not_time\nP_nT_nS&lt;-P_no_scope*T_not_time\n\nP_T_S\n\n#&gt; [1] 0.06\n\nP_T_nS\n\n#&gt; [1] 0.42\n\nP_nT_S\n\n#&gt; [1] 0.24\n\nP_nT_nS\n\n#&gt; [1] 0.28\n\nsum_P&lt;-P_T_S+P_T_nS+P_nT_S+P_nT_nS\n\nsum_P\n\n#&gt; [1] 1\n\n\n\n\n2 Assingment 2\nWhat is the percentage of customers using all three devices?\n0.5%\nWhat is the percentage of customers using at least two devices?\n19.4%\nWhat is the percentage of customers using only one device?\n80.1%\n\n\n3 Assingment 3\n\nP_A&lt;-0.04\nP_nA&lt;-1-P_A\nP_BA&lt;-0.97\nP_BnA&lt;-0.01\n\nP_B&lt;-P_BA*P_A+P_BnA*P_nA\nP_AB&lt;-(P_BA*P_A)/P_B\nP_nAB&lt;-(P_BnA*P_nA)/P_B\n\nprint(P_AB)\n\n#&gt; [1] 0.8016529\n\nprint(P_nAB)\n\n#&gt; [1] 0.1983471\n\n\nThese results show that in case the alarm is triggered, there is a possibility of about 20% that the product is flawless and a probability of 80% that the product is faulty."
  },
  {
    "objectID": "content/01_journal/02_statistics.html",
    "href": "content/01_journal/02_statistics.html",
    "title": "Statistical Concepts",
    "section": "",
    "text": "#Assingment\n\nlibrary(magrittr) \nlibrary(dplyr) \n\n\nAttache Paket: 'dplyr'\n\n\nDie folgenden Objekte sind maskiert von 'package:stats':\n\n    filter, lag\n\n\nDie folgenden Objekte sind maskiert von 'package:base':\n\n    intersect, setdiff, setequal, union\n\nrandom_vars &lt;- readRDS(\"data/random_vars.rds\")\n\nView(random_vars)\n\nmean_var1 &lt;- mean(random_vars$age)\nvariance_var1 &lt;- var(random_vars$age)\nstd_var1 &lt;- sd(random_vars$age)\n\nmean_var2 &lt;- mean(random_vars$income)\nvariance_var2 &lt;- var(random_vars$income)\nstd_var2 &lt;- sd(random_vars$income)\n\nprint(mean_var1)\n\n[1] 33.471\n\nprint(variance_var1)\n\n[1] 340.6078\n\nprint(std_var1)\n\n[1] 18.45556\n\nprint(mean_var2)\n\n[1] 3510.731\n\nprint(variance_var2)\n\n[1] 8625646\n\nprint(std_var2)\n\n[1] 2936.945\n\ncovariance &lt;- cov(random_vars$age, random_vars$income)\ncorrelation &lt;- cor(random_vars$age, random_vars$income)\n\nprint(\"covariance\")\n\n[1] \"covariance\"\n\nprint(covariance)\n\n[1] 29700.15\n\nprint(\"correlation\")\n\n[1] \"correlation\"\n\nprint(correlation)\n\n[1] 0.5479432\n\ndf_sub18 &lt;- subset(random_vars, age &gt;= 18)\ndf_sub18_65 &lt;- subset(random_vars, age &gt;= 18 & age &lt;= 65)\ndf_sub65 &lt;- subset(random_vars, age &lt;= 65)\n\nmean_df_sub18 &lt;- mean(df_sub18$income)\nmean_df_sub18_65 &lt;- mean(df_sub18_65$income)\nmean_df_sub65 &lt;- mean(df_sub65$income)\n\nmean_df_sub18\n\n[1] 4464.027\n\nmean_df_sub18_65\n\n[1] 4691.378\n\nmean_df_sub65\n\n[1] 3625.972"
  },
  {
    "objectID": "content/01_journal/04_causality.html",
    "href": "content/01_journal/04_causality.html",
    "title": "Causality",
    "section": "",
    "text": "##Assignment\n\nlibrary(ggplot2)\nlibrary(dplyr)\n#source: https://tylervigen.com/spurious-correlations \nmonth &lt;- c(1:12)\nice_cream_consumption &lt;- c(50, 48, 40, 35, 30, 25, 15, 12, 25, 35, 48, 55)\ndrownings &lt;- c(10, 15, 20, 25, 30, 40, 55, 60, 45, 35, 22, 15)\n\ndf1 &lt;- data.frame(month, ice_cream_consumption)\ndf2 &lt;- data.frame(month, drownings)\n\n\nggplot() +\n  geom_line(data = df1, aes(x = month, y = ice_cream_consumption, color = \"Ice Cream Consumption\"), linetype = \"solid\") +\n  geom_line(data = df2, aes(x = month, y = drownings, color = \"Number of Drownings\"), linetype = \"dashed\") +\n  scale_y_continuous(name = \"Ice Cream Consumption\", sec.axis = sec_axis(~., name = \"Number of Drownings\")) +\n  scale_color_manual(values = c(\"Ice Cream Consumption\" = \"blue\", \"Number of Drownings\" = \"red\")) +\n  labs(x = \"Month\") +\n  ggtitle(\"Two Line Plots: Ice Cream and Drowning\")"
  },
  {
    "objectID": "content/01_journal/06_rct.html",
    "href": "content/01_journal/06_rct.html",
    "title": "Randomized Controlled Trials",
    "section": "",
    "text": "# Load necessary libraries\nlibrary(tidyverse)\n\nWarning: Paket 'tidyverse' wurde unter R Version 4.3.2 erstellt\n\n\nWarning: Paket 'tidyr' wurde unter R Version 4.3.2 erstellt\n\n\nWarning: Paket 'readr' wurde unter R Version 4.3.2 erstellt\n\n\nWarning: Paket 'purrr' wurde unter R Version 4.3.2 erstellt\n\n\nWarning: Paket 'forcats' wurde unter R Version 4.3.2 erstellt\n\n\nWarning: Paket 'lubridate' wurde unter R Version 4.3.2 erstellt\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# Load the data\nabtest_data &lt;- readRDS(\"C:\\\\Users\\\\Deniz\\\\Documents\\\\GitHub\\\\Causal_Data_Science_Data\\\\abtest_online.rds\")\n\n# Explore the data\nhead(abtest_data)\n\n# A tibble: 6 × 6\n  ip              chatbot previous_visit mobile_device purchase purchase_amount\n  &lt;chr&gt;           &lt;lgl&gt;            &lt;dbl&gt; &lt;lgl&gt;            &lt;dbl&gt;           &lt;dbl&gt;\n1 161.88.211.70   TRUE                 0 FALSE                0             0  \n2 239.86.201.0    TRUE                 1 FALSE                1            39.5\n3 35.90.22.130    TRUE                 1 FALSE                0             0  \n4 219.176.193.3   FALSE                4 TRUE                 0             0  \n5 247.85.168.16   TRUE                 1 FALSE                0             0  \n6 120.221.249.244 TRUE                 2 FALSE                0             0  \n\nsummary(abtest_data)\n\n      ip             chatbot        previous_visit   mobile_device  \n Length:1000        Mode :logical   Min.   : 0.000   Mode :logical  \n Class :character   FALSE:496       1st Qu.: 1.000   FALSE:683      \n Mode  :character   TRUE :504       Median : 1.000   TRUE :317      \n                                    Mean   : 2.021                  \n                                    3rd Qu.: 3.000                  \n                                    Max.   :13.000                  \n    purchase     purchase_amount\n Min.   :0.000   Min.   : 0.00  \n 1st Qu.:0.000   1st Qu.: 0.00  \n Median :0.000   Median : 0.00  \n Mean   :0.381   Mean   :13.14  \n 3rd Qu.:1.000   3rd Qu.:27.44  \n Max.   :1.000   Max.   :81.35  \n\n# Check covariate balance across groups\ncovariate_balance_plot &lt;- ggplot(abtest_data, aes(x = chatbot, y = mobile_device, color = chatbot)) +\n  geom_boxplot() +\n  labs(title = \"Covariate Balance Check\",\n       x = \"Chatbot\",\n       y = \"Mobile Device\") +\n  theme_minimal()\n\n# Display covariate balance plot\nprint(covariate_balance_plot)\n\n\n\n\n\n\n\n# Run a regression to find the effect of chatbot on sales (purchase_amount)\nregression_model &lt;- lm(purchase_amount ~ chatbot + mobile_device + previous_visit, data = abtest_data)\nsummary(regression_model)\n\n\nCall:\nlm(formula = purchase_amount ~ chatbot + mobile_device + previous_visit, \n    data = abtest_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.414 -14.428  -8.435  12.559  64.584 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        15.2840     1.1227  13.614  &lt; 2e-16 ***\nchatbotTRUE        -6.8488     1.1792  -5.808 8.49e-09 ***\nmobile_deviceTRUE  -0.8562     1.2642  -0.677  0.49841    \nprevious_visit      0.7792     0.2869   2.716  0.00673 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 18.6 on 996 degrees of freedom\nMultiple R-squared:  0.04243,   Adjusted R-squared:  0.03954 \nF-statistic: 14.71 on 3 and 996 DF,  p-value: 2.228e-09\n\n# Find subgroup-specific effects by including an interaction term\ninteraction_model &lt;- lm(purchase_amount ~ chatbot * mobile_device + previous_visit, data = abtest_data)\nsummary(interaction_model)\n\n\nCall:\nlm(formula = purchase_amount ~ chatbot * mobile_device + previous_visit, \n    data = abtest_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.403 -14.450  -8.445  12.549  64.562 \n\nCoefficients:\n                              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                   15.27384    1.19130  12.821  &lt; 2e-16 ***\nchatbotTRUE                   -6.82837    1.42580  -4.789 1.93e-06 ***\nmobile_deviceTRUE             -0.82375    1.79309  -0.459  0.64605    \nprevious_visit                 0.77914    0.28711   2.714  0.00677 ** \nchatbotTRUE:mobile_deviceTRUE -0.06455    2.52907  -0.026  0.97964    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 18.6 on 995 degrees of freedom\nMultiple R-squared:  0.04243,   Adjusted R-squared:  0.03858 \nF-statistic: 11.02 on 4 and 995 DF,  p-value: 9.485e-09\n\n# Compute CATE for mobile users\nmobile_users_effect &lt;- coef(interaction_model)[\"chatbotTRUE:mobile_deviceTRUE\"]\n\n# Run a logistic regression for binary outcome (purchase)\nlogistic_model &lt;- glm(purchase ~ chatbot + mobile_device + previous_visit, \n                      family = binomial(link = 'logit'), data = abtest_data)\nsummary(logistic_model)\n\n\nCall:\nglm(formula = purchase ~ chatbot + mobile_device + previous_visit, \n    family = binomial(link = \"logit\"), data = abtest_data)\n\nCoefficients:\n                  Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)       -0.22185    0.12347  -1.797  0.07237 .  \nchatbotTRUE       -0.96894    0.13564  -7.144 9.09e-13 ***\nmobile_deviceTRUE -0.07119    0.14530  -0.490  0.62417    \nprevious_visit     0.10606    0.03262   3.252  0.00115 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1329.1  on 999  degrees of freedom\nResidual deviance: 1262.2  on 996  degrees of freedom\nAIC: 1270.2\n\nNumber of Fisher Scoring iterations: 4\n\n\n\nchatbotTRUE: The estimated change in purchase_amount when chatbot is TRUE compared to when it is FALSE. A negative coefficient suggests that the presence of a chatbot is associated with a decrease in purchase_amount.\nThe CATE for mobile users (chatbotTRUE:mobile_deviceTRUE)is -0.06455 in the model. However, this coefficient is not statistically significant, indicating that there is no significant distinction in the impact of the chatbot on sales (purchase_amount) between mobile and non-mobile users.\nCoefficient for chatbotTRUE in the logistic regression model is -0.96894. Therefore:\n\nA negative coefficient suggests that the presence of the chatbot is associated with a decrease in the log-odds of making a purchase compared to when the chatbot is not present. It implies that customers exposed to the chatbot are less likely to make a purchase (purchase = 1) compared to those not exposed, according to the model."
  },
  {
    "objectID": "content/01_journal/08_did.html",
    "href": "content/01_journal/08_did.html",
    "title": "Difference-in-Differences",
    "section": "",
    "text": "library(dplyr)\ndf &lt;- readRDS(\"data/hospdd.rds\")\nstr(df)\n\ntibble [7,368 × 5] (S3: tbl_df/tbl/data.frame)\n $ hospital : num [1:7368] 1 1 1 1 1 1 1 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Hospital ID\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ frequency: 'int' num [1:7368] 3 2 4 2 1 1 2 4 2 2 ...\n  ..- attr(*, \"label\")= chr \"Hospital visit frequency\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n  ..- attr(*, \"labels\")= Named num [1:4] 1 2 3 4\n  .. ..- attr(*, \"names\")= chr [1:4] \"Low\" \"Medium\" \"High\" \"Very high\"\n $ month    : 'int' num [1:7368] 7 3 2 4 3 7 4 1 3 1 ...\n  ..- attr(*, \"label\")= chr \"Month\"\n  ..- attr(*, \"format.stata\")= chr \"%8.0g\"\n  ..- attr(*, \"labels\")= Named num [1:7] 1 2 3 4 5 6 7\n  .. ..- attr(*, \"names\")= chr [1:7] \"January\" \"February\" \"March\" \"April\" ...\n $ procedure: 'dbl' num [1:7368] 1 0 0 1 0 1 1 0 0 0 ...\n  ..- attr(*, \"label\")= chr \"Admission procedure\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n  ..- attr(*, \"labels\")= Named num [1:2] 0 1\n  .. ..- attr(*, \"names\")= chr [1:2] \"Old\" \"New\"\n $ satis    : num [1:7368] 4.11 3.32 3.41 3 3.11 ...\n  ..- attr(*, \"label\")= chr \"Patient satisfaction score\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n - attr(*, \"label\")= chr \"Artificial hospital admission procedure data\"\n\n# Select the hospitals for which the new admission procedure will be applied\nnew_procedure_hospitals &lt;- unique(df$hospital[df$procedure == 1])\nnew_procedure_hospitals\n\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18\n\ntreated_data &lt;- df %&gt;% filter(hospital %in% new_procedure_hospitals)\nmean_satisfaction_tb &lt;- treated_data %&gt;% filter(month == 3) %&gt;% summarise(mean_satisfaction_tb = mean(satis, na.rm = TRUE)) %&gt;% pull(mean_satisfaction_tb)\nmean_satisfaction_ta &lt;- treated_data %&gt;% filter(month == 4) %&gt;% summarise(mean_satisfaction_ta = mean(satis, na.rm = TRUE)) %&gt;% pull(mean_satisfaction_ta)\n\ncontrol_data &lt;- df %&gt;% filter(!hospital %in% new_procedure_hospitals)\nmean_satisfaction_cb &lt;- control_data %&gt;% filter(month == 3) %&gt;% summarise(mean_satisfaction_cb = mean(satis, na.rm = TRUE)) %&gt;% pull(mean_satisfaction_cb)\nmean_satisfaction_ca &lt;- control_data %&gt;% filter(month == 4) %&gt;% summarise(mean_satisfaction_ca = mean(satis, na.rm = TRUE)) %&gt;% pull(mean_satisfaction_ca)\n\nDiD_estimate_b &lt;- mean_satisfaction_ta - mean_satisfaction_cb\nDiD_estimate_a &lt;- mean_satisfaction_tb - mean_satisfaction_ca\n\nDiD &lt;- DiD_estimate_a - DiD_estimate_b\ncat(\"Estimated DiD: \", DiD)\n\nEstimated DiD:  -0.7932465\n\nmodel1 &lt;- lm(satis ~ procedure + month + hospital, data = df)\nsummary(model1)\n\n\nCall:\nlm(formula = satis ~ procedure + month + hospital, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.3126 -0.6548 -0.0933  0.5555  5.3347 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  3.538024   0.031365 112.801  &lt; 2e-16 ***\nprocedure    0.886120   0.039143  22.638  &lt; 2e-16 ***\nmonth       -0.004965   0.006392  -0.777 0.437378    \nhospital    -0.003731   0.001043  -3.576 0.000351 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9836 on 7364 degrees of freedom\nMultiple R-squared:  0.1325,    Adjusted R-squared:  0.1321 \nF-statistic: 374.8 on 3 and 7364 DF,  p-value: &lt; 2.2e-16\n\nmodel2 &lt;- lm(satis ~ procedure + as.factor(month) + as.factor(hospital), data = df)\nsummary(model2)\n\n\nCall:\nlm(formula = satis ~ procedure + as.factor(month) + as.factor(hospital), \n    data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.1880 -0.4644  0.0067  0.4539  4.2921 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)            3.1716566  0.0562207  56.414  &lt; 2e-16 ***\nprocedure              0.8479879  0.0342191  24.781  &lt; 2e-16 ***\nas.factor(month)2     -0.0096077  0.0292119  -0.329 0.742244    \nas.factor(month)3      0.0219686  0.0292119   0.752 0.452050    \nas.factor(month)4     -0.0032839  0.0324936  -0.101 0.919504    \nas.factor(month)5     -0.0094027  0.0324936  -0.289 0.772305    \nas.factor(month)6     -0.0038375  0.0324936  -0.118 0.905990    \nas.factor(month)7     -0.0111941  0.0324936  -0.345 0.730478    \nas.factor(hospital)2   0.4085664  0.0772418   5.289 1.26e-07 ***\nas.factor(hospital)3   0.5336248  0.0793384   6.726 1.88e-11 ***\nas.factor(hospital)4   0.2275102  0.0739411   3.077 0.002099 ** \nas.factor(hospital)5  -0.1453529  0.0739411  -1.966 0.049360 *  \nas.factor(hospital)6   0.4478634  0.0739411   6.057 1.46e-09 ***\nas.factor(hospital)7   1.4044164  0.0714559  19.654  &lt; 2e-16 ***\nas.factor(hospital)8   0.0718758  0.0763186   0.942 0.346333    \nas.factor(hospital)9  -1.5185150  0.0782447 -19.407  &lt; 2e-16 ***\nas.factor(hospital)10  1.6828446  0.0772418  21.787  &lt; 2e-16 ***\nas.factor(hospital)11  0.2209653  0.0763186   2.895 0.003799 ** \nas.factor(hospital)12 -0.0953034  0.0782447  -1.218 0.223256    \nas.factor(hospital)13  0.4955931  0.0754658   6.567 5.48e-11 ***\nas.factor(hospital)14  0.2330426  0.0793384   2.937 0.003321 ** \nas.factor(hospital)15 -0.1444935  0.0793384  -1.821 0.068613 .  \nas.factor(hospital)16  1.4142680  0.0772418  18.310  &lt; 2e-16 ***\nas.factor(hospital)17  0.4235429  0.0805362   5.259 1.49e-07 ***\nas.factor(hospital)18  0.1532761  0.0938164   1.634 0.102346    \nas.factor(hospital)19 -0.7453017  0.0811623  -9.183  &lt; 2e-16 ***\nas.factor(hospital)20  0.0473874  0.0791140   0.599 0.549207    \nas.factor(hospital)21  1.1943370  0.0836232  14.282  &lt; 2e-16 ***\nas.factor(hospital)22  0.7993153  0.0823336   9.708  &lt; 2e-16 ***\nas.factor(hospital)23  0.7017202  0.0811623   8.646  &lt; 2e-16 ***\nas.factor(hospital)24 -0.3081260  0.0866402  -3.556 0.000378 ***\nas.factor(hospital)25  0.6464736  0.0927258   6.972 3.40e-12 ***\nas.factor(hospital)26  0.2142471  0.0791140   2.708 0.006783 ** \nas.factor(hospital)27 -0.3986544  0.0766106  -5.204 2.01e-07 ***\nas.factor(hospital)28  0.7119953  0.0836232   8.514  &lt; 2e-16 ***\nas.factor(hospital)29  0.2485512  0.0800935   3.103 0.001921 ** \nas.factor(hospital)30 -0.1679220  0.0953638  -1.761 0.078304 .  \nas.factor(hospital)31  0.5120848  0.0791140   6.473 1.02e-10 ***\nas.factor(hospital)32 -0.3233456  0.0800935  -4.037 5.47e-05 ***\nas.factor(hospital)33 -0.4539752  0.0791140  -5.738 9.95e-09 ***\nas.factor(hospital)34 -0.0004123  0.0746054  -0.006 0.995590    \nas.factor(hospital)35  0.3541110  0.0766106   4.622 3.86e-06 ***\nas.factor(hospital)36  2.1381425  0.0773811  27.631  &lt; 2e-16 ***\nas.factor(hospital)37  0.1404036  0.0927258   1.514 0.130023    \nas.factor(hospital)38 -0.0868060  0.0782129  -1.110 0.267093    \nas.factor(hospital)39 -0.0234969  0.0823336  -0.285 0.775356    \nas.factor(hospital)40  1.1215331  0.0782129  14.339  &lt; 2e-16 ***\nas.factor(hospital)41 -0.1497346  0.0766106  -1.954 0.050681 .  \nas.factor(hospital)42  0.8811369  0.0850508  10.360  &lt; 2e-16 ***\nas.factor(hospital)43 -0.7724325  0.0811623  -9.517  &lt; 2e-16 ***\nas.factor(hospital)44  0.0344120  0.0904337   0.381 0.703569    \nas.factor(hospital)45 -0.2137495  0.0766106  -2.790 0.005283 ** \nas.factor(hospital)46  0.0784915  0.0823336   0.953 0.340452    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.7238 on 7315 degrees of freedom\nMultiple R-squared:  0.5333,    Adjusted R-squared:  0.5299 \nF-statistic: 160.7 on 52 and 7315 DF,  p-value: &lt; 2.2e-16\n\n\nThe main difference between including variables directly and as factors is how they are treated. When treated as factors, each unique value or level of the variable is considered a separate category. This means that for each hospital or month, different effects can be observed individually."
  },
  {
    "objectID": "content/01_journal/10_rdd.html",
    "href": "content/01_journal/10_rdd.html",
    "title": "Regression Discontinuity",
    "section": "",
    "text": "As can be observed from the code below, the results do not appear to be very sensitive to a reduction in the bandwidth. The local average treatment effect changes from 7.99 to 7.36, which is a small change considering the bandwidth was halved (a relative change of 8%). However, the slope of the average treatment effect appears to be steeper than before.\n\nlibrary(estimatr)\n\nWarning: Paket 'estimatr' wurde unter R Version 4.3.2 erstellt\n\nlibrary(ggdag)\n\nWarning: Paket 'ggdag' wurde unter R Version 4.3.2 erstellt\n\n\n\nAttache Paket: 'ggdag'\n\n\nDas folgende Objekt ist maskiert 'package:stats':\n\n    filter\n\nlibrary(ggplot2)\nlibrary(dplyr)\n\n\nAttache Paket: 'dplyr'\n\n\nDie folgenden Objekte sind maskiert von 'package:stats':\n\n    filter, lag\n\n\nDie folgenden Objekte sind maskiert von 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidyverse)\n\nWarning: Paket 'tidyverse' wurde unter R Version 4.3.2 erstellt\n\n\nWarning: Paket 'tidyr' wurde unter R Version 4.3.2 erstellt\n\n\nWarning: Paket 'readr' wurde unter R Version 4.3.2 erstellt\n\n\nWarning: Paket 'purrr' wurde unter R Version 4.3.2 erstellt\n\n\nWarning: Paket 'forcats' wurde unter R Version 4.3.2 erstellt\n\n\nWarning: Paket 'lubridate' wurde unter R Version 4.3.2 erstellt\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ lubridate 1.9.3     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.0\n✔ readr     2.1.4     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks ggdag::filter(), stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ndf &lt;- readRDS(\"data/coupon.rds\")\n\nc0 &lt;- 60\nbw &lt;- c0 + c(-2.5, 2.5)\n\n# Subsets below and above threshold in specified bandwidth\ndf_bw_below &lt;- df %&gt;% filter(days_since_last &gt;= bw[1] & days_since_last &lt; c0)\ndf_bw_above &lt;- df %&gt;% filter(days_since_last &gt;= c0 & days_since_last &lt;= bw[2])\n\nmodel_bw_below &lt;- lm(purchase_after ~ days_since_last, df_bw_below)\nmodel_bw_above &lt;- lm(purchase_after ~ days_since_last, df_bw_above)\n\ny0 &lt;- predict(model_bw_below, tibble(days_since_last = c0))\ny1 &lt;- predict(model_bw_above, tibble(days_since_last = c0))\n\nlate &lt;- y1 - y0\nsprintf(\"LATE: %.2f\", late)\n\n[1] \"LATE: 7.36\"\n\ndf_bw &lt;- bind_rows(df_bw_above, df_bw_below)\nmin_y &lt;- min(df_bw$purchase_after)\nmax_y &lt;- max(df_bw$purchase_after)\n\n# Add lines for vertical distance and change limits of x-axis.\ndep_var_bw &lt;- \n  ggplot(df_bw, aes(x = days_since_last, y = purchase_after, color = coupon)) +\n  geom_vline(xintercept = c0, color = \"blue\", linewidth = 2) +\n  geom_point(alpha = 0.4, size = 1) +\n  geom_smooth(data = df_bw_below, method = \"lm\", se = F, linewidth = 2) +\n  geom_smooth(data = df_bw_above, method = \"lm\", se = F, linewidth = 2) +\n  geom_segment(aes(x = c0, xend = bw[2], y = y0, yend = y0),\n               linetype = \"dotted\", color = \"red\") +\n  geom_segment(aes(x = bw[1], xend = c0, y = y1, yend = y1),\n               linetype = \"dotted\", color = \"red\") +\n  annotate(\"text\", x = c0+2, y = mean(c(y1, y0)-2),\n           label = sprintf(\"Difference: %.2f\", (y1 - y0)),\n           color = \"green\", fontface = 2) +\n  scale_y_continuous(limits = c(min_y, max_y)) + \n  scale_color_discrete(labels = c(\"No coupon\", \"Coupon\")) +\n  xlab(\"Days since last purchase\") +\n  ylab(\"Purchase after coupon assignment\") +\n  theme(legend.title = element_blank())\ndep_var_bw\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\nDoubling the bandwidth increases the LATE by a factor of 1,19. The average treatment effect appears almost constant aside from the jump at the cut-off point.\n\ndf &lt;- readRDS(\"data/coupon.rds\")\n\nc0 &lt;- 60\nbw &lt;- c0 + c(-10, 10)\n\n# Subsets below and above threshold in specified bandwidth\ndf_bw_below &lt;- df %&gt;% filter(days_since_last &gt;= bw[1] & days_since_last &lt; c0)\ndf_bw_above &lt;- df %&gt;% filter(days_since_last &gt;= c0 & days_since_last &lt;= bw[2])\n\nmodel_bw_below &lt;- lm(purchase_after ~ days_since_last, df_bw_below)\nmodel_bw_above &lt;- lm(purchase_after ~ days_since_last, df_bw_above)\n\ny0 &lt;- predict(model_bw_below, tibble(days_since_last = c0))\ny1 &lt;- predict(model_bw_above, tibble(days_since_last = c0))\n\nlate &lt;- y1 - y0\nsprintf(\"LATE: %.2f\", late)\n\n[1] \"LATE: 9.51\"\n\ndf_bw &lt;- bind_rows(df_bw_above, df_bw_below)\nmin_y &lt;- min(df_bw$purchase_after)\nmax_y &lt;- max(df_bw$purchase_after)\n\n# Add lines for vertical distance and change limits of x-axis.\ndep_var_bw &lt;- \n  ggplot(df_bw, aes(x = days_since_last, y = purchase_after, color = coupon)) +\n  geom_vline(xintercept = c0, color = \"blue\", linewidth = 2) +\n  geom_point(alpha = 0.4, size = 1) +\n  geom_smooth(data = df_bw_below, method = \"lm\", se = F, linewidth = 2) +\n  geom_smooth(data = df_bw_above, method = \"lm\", se = F, linewidth = 2) +\n  geom_segment(aes(x = c0, xend = bw[2], y = y0, yend = y0),\n               linetype = \"dotted\", color = \"red\") +\n  geom_segment(aes(x = bw[1], xend = c0, y = y1, yend = y1),\n               linetype = \"dotted\", color = \"red\") +\n  annotate(\"text\", x = c0+2, y = mean(c(y1, y0)-2),\n           label = sprintf(\"Difference: %.2f\", (y1 - y0)),\n           color = \"green\", fontface = 2) +\n  scale_y_continuous(limits = c(min_y, max_y)) + \n  scale_color_discrete(labels = c(\"No coupon\", \"Coupon\")) +\n  xlab(\"Days since last purchase\") +\n  ylab(\"Purchase after coupon assignment\") +\n  theme(legend.title = element_blank())\ndep_var_bw\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "content/01_journal/10_rdd.html#results-with-half-the-bandwidth",
    "href": "content/01_journal/10_rdd.html#results-with-half-the-bandwidth",
    "title": "Regression Discontinuity",
    "section": "",
    "text": "As can be observed from the code below, the results do not appear to be very sensitive to a reduction in the bandwidth. The local average treatment effect changes from 7.99 to 7.36, which is a small change considering the bandwidth was halved (a relative change of 8%). However, the slope of the average treatment effect appears to be steeper than before.\n\nlibrary(estimatr)\n\nWarning: Paket 'estimatr' wurde unter R Version 4.3.2 erstellt\n\nlibrary(ggdag)\n\nWarning: Paket 'ggdag' wurde unter R Version 4.3.2 erstellt\n\n\n\nAttache Paket: 'ggdag'\n\n\nDas folgende Objekt ist maskiert 'package:stats':\n\n    filter\n\nlibrary(ggplot2)\nlibrary(dplyr)\n\n\nAttache Paket: 'dplyr'\n\n\nDie folgenden Objekte sind maskiert von 'package:stats':\n\n    filter, lag\n\n\nDie folgenden Objekte sind maskiert von 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidyverse)\n\nWarning: Paket 'tidyverse' wurde unter R Version 4.3.2 erstellt\n\n\nWarning: Paket 'tidyr' wurde unter R Version 4.3.2 erstellt\n\n\nWarning: Paket 'readr' wurde unter R Version 4.3.2 erstellt\n\n\nWarning: Paket 'purrr' wurde unter R Version 4.3.2 erstellt\n\n\nWarning: Paket 'forcats' wurde unter R Version 4.3.2 erstellt\n\n\nWarning: Paket 'lubridate' wurde unter R Version 4.3.2 erstellt\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ lubridate 1.9.3     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.0\n✔ readr     2.1.4     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks ggdag::filter(), stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ndf &lt;- readRDS(\"data/coupon.rds\")\n\nc0 &lt;- 60\nbw &lt;- c0 + c(-2.5, 2.5)\n\n# Subsets below and above threshold in specified bandwidth\ndf_bw_below &lt;- df %&gt;% filter(days_since_last &gt;= bw[1] & days_since_last &lt; c0)\ndf_bw_above &lt;- df %&gt;% filter(days_since_last &gt;= c0 & days_since_last &lt;= bw[2])\n\nmodel_bw_below &lt;- lm(purchase_after ~ days_since_last, df_bw_below)\nmodel_bw_above &lt;- lm(purchase_after ~ days_since_last, df_bw_above)\n\ny0 &lt;- predict(model_bw_below, tibble(days_since_last = c0))\ny1 &lt;- predict(model_bw_above, tibble(days_since_last = c0))\n\nlate &lt;- y1 - y0\nsprintf(\"LATE: %.2f\", late)\n\n[1] \"LATE: 7.36\"\n\ndf_bw &lt;- bind_rows(df_bw_above, df_bw_below)\nmin_y &lt;- min(df_bw$purchase_after)\nmax_y &lt;- max(df_bw$purchase_after)\n\n# Add lines for vertical distance and change limits of x-axis.\ndep_var_bw &lt;- \n  ggplot(df_bw, aes(x = days_since_last, y = purchase_after, color = coupon)) +\n  geom_vline(xintercept = c0, color = \"blue\", linewidth = 2) +\n  geom_point(alpha = 0.4, size = 1) +\n  geom_smooth(data = df_bw_below, method = \"lm\", se = F, linewidth = 2) +\n  geom_smooth(data = df_bw_above, method = \"lm\", se = F, linewidth = 2) +\n  geom_segment(aes(x = c0, xend = bw[2], y = y0, yend = y0),\n               linetype = \"dotted\", color = \"red\") +\n  geom_segment(aes(x = bw[1], xend = c0, y = y1, yend = y1),\n               linetype = \"dotted\", color = \"red\") +\n  annotate(\"text\", x = c0+2, y = mean(c(y1, y0)-2),\n           label = sprintf(\"Difference: %.2f\", (y1 - y0)),\n           color = \"green\", fontface = 2) +\n  scale_y_continuous(limits = c(min_y, max_y)) + \n  scale_color_discrete(labels = c(\"No coupon\", \"Coupon\")) +\n  xlab(\"Days since last purchase\") +\n  ylab(\"Purchase after coupon assignment\") +\n  theme(legend.title = element_blank())\ndep_var_bw\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "content/01_journal/10_rdd.html#results-with-twice-the-bandwidth",
    "href": "content/01_journal/10_rdd.html#results-with-twice-the-bandwidth",
    "title": "Regression Discontinuity",
    "section": "",
    "text": "Doubling the bandwidth increases the LATE by a factor of 1,19. The average treatment effect appears almost constant aside from the jump at the cut-off point.\n\ndf &lt;- readRDS(\"data/coupon.rds\")\n\nc0 &lt;- 60\nbw &lt;- c0 + c(-10, 10)\n\n# Subsets below and above threshold in specified bandwidth\ndf_bw_below &lt;- df %&gt;% filter(days_since_last &gt;= bw[1] & days_since_last &lt; c0)\ndf_bw_above &lt;- df %&gt;% filter(days_since_last &gt;= c0 & days_since_last &lt;= bw[2])\n\nmodel_bw_below &lt;- lm(purchase_after ~ days_since_last, df_bw_below)\nmodel_bw_above &lt;- lm(purchase_after ~ days_since_last, df_bw_above)\n\ny0 &lt;- predict(model_bw_below, tibble(days_since_last = c0))\ny1 &lt;- predict(model_bw_above, tibble(days_since_last = c0))\n\nlate &lt;- y1 - y0\nsprintf(\"LATE: %.2f\", late)\n\n[1] \"LATE: 9.51\"\n\ndf_bw &lt;- bind_rows(df_bw_above, df_bw_below)\nmin_y &lt;- min(df_bw$purchase_after)\nmax_y &lt;- max(df_bw$purchase_after)\n\n# Add lines for vertical distance and change limits of x-axis.\ndep_var_bw &lt;- \n  ggplot(df_bw, aes(x = days_since_last, y = purchase_after, color = coupon)) +\n  geom_vline(xintercept = c0, color = \"blue\", linewidth = 2) +\n  geom_point(alpha = 0.4, size = 1) +\n  geom_smooth(data = df_bw_below, method = \"lm\", se = F, linewidth = 2) +\n  geom_smooth(data = df_bw_above, method = \"lm\", se = F, linewidth = 2) +\n  geom_segment(aes(x = c0, xend = bw[2], y = y0, yend = y0),\n               linetype = \"dotted\", color = \"red\") +\n  geom_segment(aes(x = bw[1], xend = c0, y = y1, yend = y1),\n               linetype = \"dotted\", color = \"red\") +\n  annotate(\"text\", x = c0+2, y = mean(c(y1, y0)-2),\n           label = sprintf(\"Difference: %.2f\", (y1 - y0)),\n           color = \"green\", fontface = 2) +\n  scale_y_continuous(limits = c(min_y, max_y)) + \n  scale_color_discrete(labels = c(\"No coupon\", \"Coupon\")) +\n  xlab(\"Days since last purchase\") +\n  ylab(\"Purchase after coupon assignment\") +\n  theme(legend.title = element_blank())\ndep_var_bw\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'"
  }
]